package gujaratiSerachEngine.Crawler.CuteCrawler;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;

public class SpiderTest
{
    /**
     * This is our test. It creates a spider (which creates spider legs) and crawls the web.
     * 
     * @param args
     *            - not used
     */
    public static void main(String[] args)
    {
    	if(args.length!=1){
    		System.out.println("Enter filename as argument(only 1) to read url list");
    		return;
    	}
    	FileReader fileReader=null;
    	BufferedReader bufferedReader = null;
    	try{
	    	File file = new File(args[0]);
	    	fileReader= new FileReader(file);
			bufferedReader = new BufferedReader(fileReader);
			//StringBuffer stringBuffer = new StringBuffer();
			String line ;
			
			Spider spider = new Spider();
			Spider.initLogFile();
		    
			while ((line = bufferedReader.readLine()) != null) {
			    spider.addUrl(line);	
			}
			if(!spider.getPagesToVisit().isEmpty()){
				spider.startCrawl();
			}
    	}
    	catch(Exception x){
    		x.printStackTrace();
    	}
    	finally {
    		try {
				bufferedReader.close();
				fileReader.close();
			} catch (IOException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
    		
		}
    }
}

